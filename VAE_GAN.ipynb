{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62e9c7cb-eb32-46df-9a22-9d15a9d39c83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models, transforms\n",
    "from torchvision.utils import save_image\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.utils as vutils\n",
    "\n",
    "device = torch.device(\"cuda\" if not torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7426dc18-a98f-4f0e-bb3c-45eddcbc7809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 클래스 정의\n",
    "class StyleTransferDataset(Dataset):\n",
    "    def __init__(self, gothic_dir, handwriting_dir, transform=None):\n",
    "        self.gothic_images = sorted([os.path.join(gothic_dir, img) for img in os.listdir(gothic_dir)])\n",
    "        self.handwriting_images = sorted([os.path.join(handwriting_dir, img) for img in os.listdir(handwriting_dir)])\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.gothic_images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        gothic_image = Image.open(self.gothic_images[idx]).convert(\"RGB\")\n",
    "        handwriting_image = Image.open(self.handwriting_images[idx]).convert(\"RGB\")\n",
    "        \n",
    "        if self.transform:\n",
    "            gothic_image = self.transform(gothic_image)\n",
    "            handwriting_image = self.transform(handwriting_image)\n",
    "        \n",
    "        return gothic_image, handwriting_image\n",
    "\n",
    "# 데이터 변환 정의\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# 데이터셋 경로 설정\n",
    "gothic_dir = '../data/FONT_GODIC_ONE/9'\n",
    "handwriting_dir = '../data/FONT_ONE/9'\n",
    "\n",
    "# 데이터셋 및 데이터로더 초기화\n",
    "dataset = StyleTransferDataset(gothic_dir, handwriting_dir, transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "217a28d3-28b0-4a47-9438-ed54a2c4c173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특징 추출기 (Encoder) 정의\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, latent_dim=128):\n",
    "        super(Encoder, self).__init__()\n",
    "        vgg_features = models.vgg19(weights=models.VGG19_Weights.IMAGENET1K_V1).features\n",
    "        self.encoder = nn.Sequential(*list(vgg_features.children())[:21])  # Conv4_1까지 사용\n",
    "        \n",
    "        # 조정된 레이어\n",
    "        self.conv = nn.Conv2d(512, 512, kernel_size=4, stride=2, padding=1)  # 추가 Conv 레이어로 크기 조정\n",
    "        self.fc_mu = nn.Linear(512 * 16 * 16, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(512 * 16 * 16, latent_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.conv(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        mu = self.fc_mu(x)\n",
    "        logvar = self.fc_logvar(x)\n",
    "        return mu, logvar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c8fd581-d1d1-4552-80ae-a5dc1f7d5829",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim=128):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.fc = nn.Linear(latent_dim, 512 * 16 * 16)\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(512, 256, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(64, 3, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        x = self.fc(z)\n",
    "        x = x.view(x.size(0), 512, 16, 16)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e39819ee-5b9e-4b82-842b-f6679138b662",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, latent_dim=128):\n",
    "        super(VAE, self).__init__()\n",
    "        self.encoder = Encoder(latent_dim)\n",
    "        self.decoder = Decoder(latent_dim)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encoder(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        recon_x = self.decoder(z)\n",
    "        return recon_x, mu, logvar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1b5547f9-a814-4463-b97d-82334d3a7783",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(256, 512, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(512, 1, kernel_size=4, stride=1, padding=0),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6aee1259-6a72-485d-9ce4-098f3cc11bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_loss_function(recon_x, x, mu, logvar):\n",
    "    recon_x = recon_x.clamp(0, 1)  # 값 범위 조정\n",
    "    x = x.clamp(0, 1)  # 값 범위 조정\n",
    "    BCE = nn.functional.binary_cross_entropy(recon_x, x, reduction='sum')\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return BCE + KLD\n",
    "\n",
    "# 모델 초기화\n",
    "latent_dim = 128\n",
    "vae = VAE(latent_dim).to(device)\n",
    "discriminator = Discriminator().to(device)\n",
    "\n",
    "# 손실 함수\n",
    "adversarial_loss = nn.BCELoss().to(device)\n",
    "\n",
    "# 옵티마이저\n",
    "optimizer_G = optim.Adam(vae.parameters(), lr=0.0001, betas=(0.5, 0.999))\n",
    "optimizer_D = optim.Adam(discriminator.parameters(), lr=0.0001, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "17f42a05-2677-4a62-8967-472f4cfac02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_generated_images(images, num_images, epoch, idx):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(\"Generated Images\")\n",
    "    images = vutils.make_grid(images[:num_images], padding=2, normalize=True)\n",
    "    images = np.transpose(images.cpu(), (1, 2, 0))\n",
    "    fname = '../data/output_images/' + str(epoch) + '_' + str(idx) + '.jpg'\n",
    "    plt.imsave(fname, images.numpy())\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ff94bf-365e-42e3-8673-3ce96e4b7183",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [1/10000], G Loss: 130567.4453, D Loss: 0.7202\n",
      "Epoch [1/10], Step [11/10000], G Loss: 127425.3359, D Loss: 0.0808\n",
      "Epoch [1/10], Step [21/10000], G Loss: 87146.9922, D Loss: 0.0541\n",
      "Epoch [1/10], Step [31/10000], G Loss: 63438.8164, D Loss: 0.0213\n",
      "Epoch [1/10], Step [41/10000], G Loss: 65542.6094, D Loss: 0.0087\n",
      "Epoch [1/10], Step [51/10000], G Loss: 63458.8086, D Loss: 0.0050\n",
      "Epoch [1/10], Step [61/10000], G Loss: 72711.0391, D Loss: 0.0035\n",
      "Epoch [1/10], Step [71/10000], G Loss: 60661.4531, D Loss: 0.0027\n",
      "Epoch [1/10], Step [81/10000], G Loss: 62347.8711, D Loss: 0.0060\n",
      "Epoch [1/10], Step [91/10000], G Loss: 61237.2734, D Loss: 0.0025\n",
      "Epoch [1/10], Step [101/10000], G Loss: 61564.5039, D Loss: 0.0015\n",
      "Epoch [1/10], Step [111/10000], G Loss: 57473.9414, D Loss: 0.0011\n",
      "Epoch [1/10], Step [121/10000], G Loss: 62711.0547, D Loss: 0.0117\n",
      "Epoch [1/10], Step [131/10000], G Loss: 54518.5820, D Loss: 0.0614\n",
      "Epoch [1/10], Step [141/10000], G Loss: 55048.2656, D Loss: 0.0015\n",
      "Epoch [1/10], Step [151/10000], G Loss: 54272.6758, D Loss: 0.0009\n",
      "Epoch [1/10], Step [161/10000], G Loss: 58138.4805, D Loss: 0.0010\n",
      "Epoch [1/10], Step [171/10000], G Loss: 66421.5859, D Loss: 0.0008\n",
      "Epoch [1/10], Step [181/10000], G Loss: 54103.2500, D Loss: 0.0009\n",
      "Epoch [1/10], Step [191/10000], G Loss: 48130.8164, D Loss: 0.0010\n",
      "Epoch [1/10], Step [201/10000], G Loss: 59240.8438, D Loss: 0.0004\n",
      "Epoch [1/10], Step [211/10000], G Loss: 51993.4062, D Loss: 0.0003\n",
      "Epoch [1/10], Step [221/10000], G Loss: 50404.4609, D Loss: 0.0003\n",
      "Epoch [1/10], Step [231/10000], G Loss: 56049.6797, D Loss: 0.0005\n",
      "Epoch [1/10], Step [241/10000], G Loss: 48578.1445, D Loss: 0.0313\n",
      "Epoch [1/10], Step [251/10000], G Loss: 48851.4297, D Loss: 0.0003\n",
      "Epoch [1/10], Step [261/10000], G Loss: 40095.8242, D Loss: 0.0005\n",
      "Epoch [1/10], Step [271/10000], G Loss: 51095.4492, D Loss: 0.0004\n",
      "Epoch [1/10], Step [281/10000], G Loss: 56834.2930, D Loss: 0.0011\n",
      "Epoch [1/10], Step [291/10000], G Loss: 46882.9180, D Loss: 0.0004\n",
      "Epoch [1/10], Step [301/10000], G Loss: 33732.1953, D Loss: 0.0022\n",
      "Epoch [1/10], Step [311/10000], G Loss: 54096.3945, D Loss: 0.8644\n",
      "Epoch [1/10], Step [321/10000], G Loss: 50619.6758, D Loss: 0.0784\n",
      "Epoch [1/10], Step [331/10000], G Loss: 57257.2539, D Loss: 0.0004\n",
      "Epoch [1/10], Step [341/10000], G Loss: 68456.7812, D Loss: 0.0018\n",
      "Epoch [1/10], Step [351/10000], G Loss: 48166.4297, D Loss: 0.0009\n",
      "Epoch [1/10], Step [361/10000], G Loss: 42984.9258, D Loss: 0.0002\n",
      "Epoch [1/10], Step [371/10000], G Loss: 46982.2383, D Loss: 0.0004\n",
      "Epoch [1/10], Step [381/10000], G Loss: 35995.2422, D Loss: 0.0001\n",
      "Epoch [1/10], Step [391/10000], G Loss: 46299.9727, D Loss: 0.0003\n",
      "Epoch [1/10], Step [401/10000], G Loss: 42028.2539, D Loss: 0.0002\n",
      "Epoch [1/10], Step [411/10000], G Loss: 34408.9570, D Loss: 0.0111\n",
      "Epoch [1/10], Step [421/10000], G Loss: 35935.1562, D Loss: 0.0004\n",
      "Epoch [1/10], Step [431/10000], G Loss: 34532.2109, D Loss: 0.1670\n",
      "Epoch [1/10], Step [441/10000], G Loss: 34809.3086, D Loss: 0.0006\n",
      "Epoch [1/10], Step [451/10000], G Loss: 61559.5938, D Loss: 0.0001\n",
      "Epoch [1/10], Step [461/10000], G Loss: 38681.8945, D Loss: 0.0001\n",
      "Epoch [1/10], Step [471/10000], G Loss: 52674.6445, D Loss: 0.0014\n",
      "Epoch [1/10], Step [481/10000], G Loss: 47739.0469, D Loss: 0.0012\n",
      "Epoch [1/10], Step [491/10000], G Loss: 47018.5703, D Loss: 0.0001\n",
      "Epoch [1/10], Step [501/10000], G Loss: 35303.8789, D Loss: 0.0001\n",
      "Epoch [1/10], Step [511/10000], G Loss: 43220.8711, D Loss: 0.0001\n",
      "Epoch [1/10], Step [521/10000], G Loss: 47742.9180, D Loss: 0.0001\n",
      "Epoch [1/10], Step [531/10000], G Loss: 34027.5742, D Loss: 0.0003\n",
      "Epoch [1/10], Step [541/10000], G Loss: 45611.1797, D Loss: 0.0001\n",
      "Epoch [1/10], Step [551/10000], G Loss: 44346.5703, D Loss: 0.0001\n",
      "Epoch [1/10], Step [561/10000], G Loss: 41927.8945, D Loss: 0.0001\n",
      "Epoch [1/10], Step [571/10000], G Loss: 42798.9492, D Loss: 0.0001\n",
      "Epoch [1/10], Step [581/10000], G Loss: 29935.1289, D Loss: 0.0001\n",
      "Epoch [1/10], Step [591/10000], G Loss: 42152.5195, D Loss: 0.0001\n",
      "Epoch [1/10], Step [601/10000], G Loss: 44578.7031, D Loss: 0.0000\n",
      "Epoch [1/10], Step [611/10000], G Loss: 48306.5156, D Loss: 0.0001\n",
      "Epoch [1/10], Step [621/10000], G Loss: 43035.9805, D Loss: 0.0001\n",
      "Epoch [1/10], Step [631/10000], G Loss: 70521.4453, D Loss: 0.0007\n",
      "Epoch [1/10], Step [641/10000], G Loss: 38950.5273, D Loss: 0.0001\n",
      "Epoch [1/10], Step [651/10000], G Loss: 32470.7402, D Loss: 0.0000\n",
      "Epoch [1/10], Step [661/10000], G Loss: 45467.1641, D Loss: 0.0000\n",
      "Epoch [1/10], Step [671/10000], G Loss: 37170.1367, D Loss: 0.0000\n",
      "Epoch [1/10], Step [681/10000], G Loss: 33096.4609, D Loss: 0.0000\n",
      "Epoch [1/10], Step [691/10000], G Loss: 48167.2188, D Loss: 0.0001\n",
      "Epoch [1/10], Step [701/10000], G Loss: 49454.8555, D Loss: 0.0001\n",
      "Epoch [1/10], Step [711/10000], G Loss: 39175.7070, D Loss: 0.0001\n",
      "Epoch [1/10], Step [721/10000], G Loss: 30752.4121, D Loss: 0.0004\n",
      "Epoch [1/10], Step [731/10000], G Loss: 53195.9648, D Loss: 0.0016\n",
      "Epoch [1/10], Step [741/10000], G Loss: 63166.5078, D Loss: 0.0011\n",
      "Epoch [1/10], Step [751/10000], G Loss: 30501.2441, D Loss: 0.2152\n",
      "Epoch [1/10], Step [761/10000], G Loss: 37045.0469, D Loss: 0.0009\n",
      "Epoch [1/10], Step [771/10000], G Loss: 33315.3633, D Loss: 0.0018\n",
      "Epoch [1/10], Step [781/10000], G Loss: 42566.2266, D Loss: 0.0001\n",
      "Epoch [1/10], Step [791/10000], G Loss: 32008.4082, D Loss: 0.0010\n",
      "Epoch [1/10], Step [801/10000], G Loss: 39305.6250, D Loss: 0.0153\n",
      "Epoch [1/10], Step [811/10000], G Loss: 36758.2578, D Loss: 0.0002\n",
      "Epoch [1/10], Step [821/10000], G Loss: 29371.5547, D Loss: 0.0003\n",
      "Epoch [1/10], Step [831/10000], G Loss: 52144.4492, D Loss: 0.0000\n",
      "Epoch [1/10], Step [841/10000], G Loss: 33433.0273, D Loss: 0.0000\n",
      "Epoch [1/10], Step [851/10000], G Loss: 40895.8438, D Loss: 0.0003\n",
      "Epoch [1/10], Step [861/10000], G Loss: 32511.3711, D Loss: 0.0001\n",
      "Epoch [1/10], Step [871/10000], G Loss: 35269.9609, D Loss: 0.0034\n",
      "Epoch [1/10], Step [881/10000], G Loss: 31906.8750, D Loss: 0.0000\n",
      "Epoch [1/10], Step [891/10000], G Loss: 32460.3438, D Loss: 0.0001\n",
      "Epoch [1/10], Step [901/10000], G Loss: 28037.5781, D Loss: 0.0000\n",
      "Epoch [1/10], Step [911/10000], G Loss: 26667.2969, D Loss: 0.0004\n",
      "Epoch [1/10], Step [921/10000], G Loss: 34911.3359, D Loss: 0.0000\n",
      "Epoch [1/10], Step [931/10000], G Loss: 48335.8750, D Loss: 0.0000\n",
      "Epoch [1/10], Step [941/10000], G Loss: 31891.4531, D Loss: 0.0000\n",
      "Epoch [1/10], Step [951/10000], G Loss: 38563.0039, D Loss: 0.0001\n",
      "Epoch [1/10], Step [961/10000], G Loss: 28666.1309, D Loss: 0.0000\n",
      "Epoch [1/10], Step [971/10000], G Loss: 30862.9629, D Loss: 0.0000\n",
      "Epoch [1/10], Step [981/10000], G Loss: 34451.7344, D Loss: 0.0000\n",
      "Epoch [1/10], Step [991/10000], G Loss: 38128.8398, D Loss: 0.0000\n",
      "Epoch [1/10], Step [1001/10000], G Loss: 37511.2930, D Loss: 0.0000\n",
      "Epoch [1/10], Step [1011/10000], G Loss: 46275.2578, D Loss: 0.0000\n",
      "Epoch [1/10], Step [1021/10000], G Loss: 33108.3633, D Loss: 0.0000\n",
      "Epoch [1/10], Step [1031/10000], G Loss: 22785.5664, D Loss: 0.0005\n",
      "Epoch [1/10], Step [1041/10000], G Loss: 46412.8867, D Loss: 0.0002\n",
      "Epoch [1/10], Step [1051/10000], G Loss: 29719.7676, D Loss: 0.0061\n",
      "Epoch [1/10], Step [1061/10000], G Loss: 30110.1621, D Loss: 0.0160\n",
      "Epoch [1/10], Step [1071/10000], G Loss: 25299.9863, D Loss: 0.0411\n",
      "Epoch [1/10], Step [1081/10000], G Loss: 40666.9023, D Loss: 0.0027\n",
      "Epoch [1/10], Step [1091/10000], G Loss: 20885.7812, D Loss: 0.1335\n",
      "Epoch [1/10], Step [1101/10000], G Loss: 43191.0078, D Loss: 0.0000\n",
      "Epoch [1/10], Step [1111/10000], G Loss: 28077.0977, D Loss: 0.1097\n",
      "Epoch [1/10], Step [1121/10000], G Loss: 44373.8516, D Loss: 0.0000\n",
      "Epoch [1/10], Step [1131/10000], G Loss: 28068.7305, D Loss: 0.0142\n",
      "Epoch [1/10], Step [1141/10000], G Loss: 29514.0137, D Loss: 0.0019\n",
      "Epoch [1/10], Step [1151/10000], G Loss: 27651.5801, D Loss: 0.0015\n",
      "Epoch [1/10], Step [1161/10000], G Loss: 50498.9727, D Loss: 0.0002\n",
      "Epoch [1/10], Step [1171/10000], G Loss: 34045.0977, D Loss: 0.0002\n",
      "Epoch [1/10], Step [1181/10000], G Loss: 23792.7207, D Loss: 0.0001\n",
      "Epoch [1/10], Step [1191/10000], G Loss: 26825.8496, D Loss: 0.0000\n",
      "Epoch [1/10], Step [1201/10000], G Loss: 25706.4512, D Loss: 0.0167\n",
      "Epoch [1/10], Step [1211/10000], G Loss: 24957.1738, D Loss: 0.0001\n",
      "Epoch [1/10], Step [1221/10000], G Loss: 31906.5762, D Loss: 0.0006\n",
      "Epoch [1/10], Step [1231/10000], G Loss: 17807.8223, D Loss: 0.6902\n",
      "Epoch [1/10], Step [1241/10000], G Loss: 30675.4395, D Loss: 0.0000\n",
      "Epoch [1/10], Step [1251/10000], G Loss: 32299.8008, D Loss: 0.0000\n",
      "Epoch [1/10], Step [1261/10000], G Loss: 34558.4570, D Loss: 0.0001\n",
      "Epoch [1/10], Step [1271/10000], G Loss: 36919.7305, D Loss: 0.0000\n",
      "Epoch [1/10], Step [1281/10000], G Loss: 33831.2969, D Loss: 0.0001\n",
      "Epoch [1/10], Step [1291/10000], G Loss: 34340.6992, D Loss: 0.0001\n",
      "Epoch [1/10], Step [1301/10000], G Loss: 52700.5781, D Loss: 0.0000\n",
      "Epoch [1/10], Step [1311/10000], G Loss: 28937.2891, D Loss: 0.0000\n",
      "Epoch [1/10], Step [1321/10000], G Loss: 31231.2188, D Loss: 0.0000\n",
      "Epoch [1/10], Step [1331/10000], G Loss: 30621.6094, D Loss: 0.0000\n",
      "Epoch [1/10], Step [1341/10000], G Loss: 34077.6445, D Loss: 0.0000\n",
      "Epoch [1/10], Step [1351/10000], G Loss: 23918.6660, D Loss: 0.0001\n",
      "Epoch [1/10], Step [1361/10000], G Loss: 53341.3242, D Loss: 0.0005\n",
      "Epoch [1/10], Step [1371/10000], G Loss: 24768.1582, D Loss: 0.0022\n",
      "Epoch [1/10], Step [1381/10000], G Loss: 25031.2246, D Loss: 0.0000\n",
      "Epoch [1/10], Step [1391/10000], G Loss: 33175.6250, D Loss: 0.0000\n",
      "Epoch [1/10], Step [1401/10000], G Loss: 52663.1250, D Loss: 0.0045\n",
      "Epoch [1/10], Step [1411/10000], G Loss: 34251.7422, D Loss: 0.0480\n",
      "Epoch [1/10], Step [1421/10000], G Loss: 30665.3516, D Loss: 0.0001\n",
      "Epoch [1/10], Step [1431/10000], G Loss: 34120.9336, D Loss: 0.0053\n",
      "Epoch [1/10], Step [1441/10000], G Loss: 35967.4922, D Loss: 0.0244\n",
      "Epoch [1/10], Step [1451/10000], G Loss: 22668.4297, D Loss: 0.0821\n",
      "Epoch [1/10], Step [1461/10000], G Loss: 41265.9219, D Loss: 0.0014\n",
      "Epoch [1/10], Step [1471/10000], G Loss: 35373.6836, D Loss: 0.0007\n",
      "Epoch [1/10], Step [1481/10000], G Loss: 24882.3340, D Loss: 0.0000\n",
      "Epoch [1/10], Step [1491/10000], G Loss: 23796.9121, D Loss: 0.0001\n",
      "Epoch [1/10], Step [1501/10000], G Loss: 44442.4141, D Loss: 0.0001\n",
      "Epoch [1/10], Step [1511/10000], G Loss: 22356.3359, D Loss: 0.0000\n",
      "Epoch [1/10], Step [1521/10000], G Loss: 38672.9531, D Loss: 0.0000\n",
      "Epoch [1/10], Step [1531/10000], G Loss: 26937.5000, D Loss: 0.0000\n",
      "Epoch [1/10], Step [1541/10000], G Loss: 16824.8418, D Loss: 0.0001\n",
      "Epoch [1/10], Step [1551/10000], G Loss: 42205.6953, D Loss: 0.0003\n",
      "Epoch [1/10], Step [1561/10000], G Loss: 29522.4648, D Loss: 0.0000\n",
      "Epoch [1/10], Step [1571/10000], G Loss: 19970.2344, D Loss: 0.0529\n",
      "Epoch [1/10], Step [1581/10000], G Loss: 28848.6738, D Loss: 0.0001\n",
      "Epoch [1/10], Step [1591/10000], G Loss: 26045.0840, D Loss: 0.0000\n",
      "Epoch [1/10], Step [1601/10000], G Loss: 33837.0000, D Loss: 0.0000\n",
      "Epoch [1/10], Step [1611/10000], G Loss: 33527.6211, D Loss: 0.0041\n",
      "Epoch [1/10], Step [1621/10000], G Loss: 30362.2402, D Loss: 0.0000\n",
      "Epoch [1/10], Step [1631/10000], G Loss: 39432.5703, D Loss: 0.0000\n",
      "Epoch [1/10], Step [1641/10000], G Loss: 29988.5527, D Loss: 0.0000\n",
      "Epoch [1/10], Step [1651/10000], G Loss: 22108.7695, D Loss: 0.0000\n",
      "Epoch [1/10], Step [1661/10000], G Loss: 30406.3047, D Loss: 0.0000\n",
      "Epoch [1/10], Step [1671/10000], G Loss: 20971.2949, D Loss: 0.0000\n",
      "Epoch [1/10], Step [1681/10000], G Loss: 27431.9805, D Loss: 0.0000\n",
      "Epoch [1/10], Step [1691/10000], G Loss: 38284.3672, D Loss: 0.0001\n",
      "Epoch [1/10], Step [1701/10000], G Loss: 26306.5195, D Loss: 0.0000\n",
      "Epoch [1/10], Step [1711/10000], G Loss: 41758.3359, D Loss: 0.0000\n",
      "Epoch [1/10], Step [1721/10000], G Loss: 24635.8477, D Loss: 0.0000\n",
      "Epoch [1/10], Step [1731/10000], G Loss: 31044.7949, D Loss: 0.0000\n",
      "Epoch [1/10], Step [1741/10000], G Loss: 29610.3828, D Loss: 0.0001\n",
      "Epoch [1/10], Step [1751/10000], G Loss: 31000.0762, D Loss: 0.0195\n",
      "Epoch [1/10], Step [1761/10000], G Loss: 28721.4492, D Loss: 0.0001\n",
      "Epoch [1/10], Step [1771/10000], G Loss: 18719.3711, D Loss: 3.2357\n",
      "Epoch [1/10], Step [1781/10000], G Loss: 34020.4727, D Loss: 0.0017\n",
      "Epoch [1/10], Step [1791/10000], G Loss: 18322.1680, D Loss: 0.0087\n",
      "Epoch [1/10], Step [1801/10000], G Loss: 32773.6484, D Loss: 0.0001\n",
      "Epoch [1/10], Step [1811/10000], G Loss: 18033.0664, D Loss: 0.0001\n",
      "Epoch [1/10], Step [1821/10000], G Loss: 18238.4922, D Loss: 0.0000\n",
      "Epoch [1/10], Step [1831/10000], G Loss: 58398.8945, D Loss: 0.0001\n",
      "Epoch [1/10], Step [1841/10000], G Loss: 22661.7441, D Loss: 0.0001\n",
      "Epoch [1/10], Step [1851/10000], G Loss: 28262.1895, D Loss: 0.0001\n",
      "Epoch [1/10], Step [1861/10000], G Loss: 31676.2148, D Loss: 0.0000\n",
      "Epoch [1/10], Step [1871/10000], G Loss: 31647.0332, D Loss: 0.0000\n",
      "Epoch [1/10], Step [1881/10000], G Loss: 29533.8613, D Loss: 0.0000\n",
      "Epoch [1/10], Step [1891/10000], G Loss: 31664.0859, D Loss: 0.0000\n",
      "Epoch [1/10], Step [1901/10000], G Loss: 40766.2461, D Loss: 0.0000\n",
      "Epoch [1/10], Step [1911/10000], G Loss: 38535.6250, D Loss: 0.0000\n",
      "Epoch [1/10], Step [1921/10000], G Loss: 25573.8848, D Loss: 0.0000\n",
      "Epoch [1/10], Step [1931/10000], G Loss: 37195.8242, D Loss: 0.0000\n",
      "Epoch [1/10], Step [1941/10000], G Loss: 47584.3906, D Loss: 0.0000\n",
      "Epoch [1/10], Step [1951/10000], G Loss: 33774.0938, D Loss: 0.0000\n",
      "Epoch [1/10], Step [1961/10000], G Loss: 58902.2500, D Loss: 0.0000\n",
      "Epoch [1/10], Step [1971/10000], G Loss: 30519.9473, D Loss: 0.0000\n",
      "Epoch [1/10], Step [1981/10000], G Loss: 28550.3477, D Loss: 0.0000\n",
      "Epoch [1/10], Step [1991/10000], G Loss: 31630.4531, D Loss: 0.0043\n",
      "Epoch [1/10], Step [2001/10000], G Loss: 22082.7324, D Loss: 0.0005\n",
      "Epoch [1/10], Step [2011/10000], G Loss: 28958.2988, D Loss: 0.0017\n",
      "Epoch [1/10], Step [2021/10000], G Loss: 29689.6855, D Loss: 0.0473\n",
      "Epoch [1/10], Step [2031/10000], G Loss: 49473.9102, D Loss: 0.0005\n",
      "Epoch [1/10], Step [2041/10000], G Loss: 22339.9199, D Loss: 0.0001\n",
      "Epoch [1/10], Step [2051/10000], G Loss: 30532.3301, D Loss: 0.0000\n",
      "Epoch [1/10], Step [2061/10000], G Loss: 28006.6621, D Loss: 0.0001\n",
      "Epoch [1/10], Step [2071/10000], G Loss: 18614.2539, D Loss: 0.0016\n",
      "Epoch [1/10], Step [2081/10000], G Loss: 27009.7930, D Loss: 0.0083\n",
      "Epoch [1/10], Step [2091/10000], G Loss: 19713.7031, D Loss: 0.0022\n",
      "Epoch [1/10], Step [2101/10000], G Loss: 19960.9160, D Loss: 0.0004\n",
      "Epoch [1/10], Step [2111/10000], G Loss: 33221.7422, D Loss: 0.0000\n",
      "Epoch [1/10], Step [2121/10000], G Loss: 33246.3945, D Loss: 0.0022\n",
      "Epoch [1/10], Step [2131/10000], G Loss: 25279.3418, D Loss: 0.0000\n",
      "Epoch [1/10], Step [2141/10000], G Loss: 27405.4395, D Loss: 0.0000\n",
      "Epoch [1/10], Step [2151/10000], G Loss: 18148.8770, D Loss: 0.0001\n",
      "Epoch [1/10], Step [2161/10000], G Loss: 26783.1191, D Loss: 0.0000\n",
      "Epoch [1/10], Step [2171/10000], G Loss: 27237.0840, D Loss: 0.0000\n",
      "Epoch [1/10], Step [2181/10000], G Loss: 29453.6699, D Loss: 0.0000\n",
      "Epoch [1/10], Step [2191/10000], G Loss: 44170.0781, D Loss: 0.0014\n",
      "Epoch [1/10], Step [2201/10000], G Loss: 22136.4785, D Loss: 0.0000\n",
      "Epoch [1/10], Step [2211/10000], G Loss: 22678.7734, D Loss: 0.0000\n",
      "Epoch [1/10], Step [2221/10000], G Loss: 18837.5332, D Loss: 0.0020\n",
      "Epoch [1/10], Step [2231/10000], G Loss: 20625.0527, D Loss: 0.0000\n",
      "Epoch [1/10], Step [2241/10000], G Loss: 26967.6211, D Loss: 0.0000\n",
      "Epoch [1/10], Step [2251/10000], G Loss: 24356.9062, D Loss: 0.0000\n",
      "Epoch [1/10], Step [2261/10000], G Loss: 23408.5527, D Loss: 0.0002\n",
      "Epoch [1/10], Step [2271/10000], G Loss: 18486.7949, D Loss: 0.0000\n",
      "Epoch [1/10], Step [2281/10000], G Loss: 44334.7539, D Loss: 0.0001\n",
      "Epoch [1/10], Step [2291/10000], G Loss: 35242.8203, D Loss: 0.0000\n",
      "Epoch [1/10], Step [2301/10000], G Loss: 34397.7500, D Loss: 0.0000\n",
      "Epoch [1/10], Step [2311/10000], G Loss: 25919.6484, D Loss: 0.0000\n",
      "Epoch [1/10], Step [2321/10000], G Loss: 25592.2891, D Loss: 0.0000\n",
      "Epoch [1/10], Step [2331/10000], G Loss: 41566.8594, D Loss: 0.0000\n",
      "Epoch [1/10], Step [2341/10000], G Loss: 24348.5449, D Loss: 0.0014\n",
      "Epoch [1/10], Step [2351/10000], G Loss: 19929.2637, D Loss: 0.0021\n",
      "Epoch [1/10], Step [2361/10000], G Loss: 27977.4043, D Loss: 0.0020\n",
      "Epoch [1/10], Step [2371/10000], G Loss: 22221.4004, D Loss: 0.0000\n",
      "Epoch [1/10], Step [2381/10000], G Loss: 24729.9863, D Loss: 0.0000\n",
      "Epoch [1/10], Step [2391/10000], G Loss: 28112.0273, D Loss: 0.0000\n",
      "Epoch [1/10], Step [2401/10000], G Loss: 34215.2461, D Loss: 0.0000\n",
      "Epoch [1/10], Step [2411/10000], G Loss: 34004.3359, D Loss: 0.0000\n",
      "Epoch [1/10], Step [2421/10000], G Loss: 20074.8965, D Loss: 0.0000\n",
      "Epoch [1/10], Step [2431/10000], G Loss: 22637.5117, D Loss: 0.0000\n",
      "Epoch [1/10], Step [2441/10000], G Loss: 22257.7363, D Loss: 0.0000\n",
      "Epoch [1/10], Step [2451/10000], G Loss: 36784.7344, D Loss: 0.0000\n",
      "Epoch [1/10], Step [2461/10000], G Loss: 33113.2148, D Loss: 0.0000\n",
      "Epoch [1/10], Step [2471/10000], G Loss: 30821.7832, D Loss: 0.0000\n",
      "Epoch [1/10], Step [2481/10000], G Loss: 24805.2480, D Loss: 0.0001\n",
      "Epoch [1/10], Step [2491/10000], G Loss: 23471.1309, D Loss: 0.0000\n",
      "Epoch [1/10], Step [2501/10000], G Loss: 35112.6758, D Loss: 0.0000\n",
      "Epoch [1/10], Step [2511/10000], G Loss: 43174.1250, D Loss: 0.0002\n",
      "Epoch [1/10], Step [2521/10000], G Loss: 16820.1016, D Loss: 0.0377\n",
      "Epoch [1/10], Step [2531/10000], G Loss: 30733.8496, D Loss: 0.0000\n",
      "Epoch [1/10], Step [2541/10000], G Loss: 39973.1875, D Loss: 0.0000\n",
      "Epoch [1/10], Step [2551/10000], G Loss: 23747.4785, D Loss: 0.0000\n",
      "Epoch [1/10], Step [2561/10000], G Loss: 29574.5605, D Loss: 0.0000\n",
      "Epoch [1/10], Step [2571/10000], G Loss: 24714.8633, D Loss: 0.0002\n",
      "Epoch [1/10], Step [2581/10000], G Loss: 31347.1270, D Loss: 0.0107\n",
      "Epoch [1/10], Step [2591/10000], G Loss: 23542.3203, D Loss: 0.0000\n",
      "Epoch [1/10], Step [2601/10000], G Loss: 21931.9766, D Loss: 0.0000\n",
      "Epoch [1/10], Step [2611/10000], G Loss: 23985.6113, D Loss: 0.0000\n",
      "Epoch [1/10], Step [2621/10000], G Loss: 18687.4180, D Loss: 0.0000\n",
      "Epoch [1/10], Step [2631/10000], G Loss: 37046.2773, D Loss: 0.0000\n",
      "Epoch [1/10], Step [2641/10000], G Loss: 24181.8047, D Loss: 0.0000\n",
      "Epoch [1/10], Step [2651/10000], G Loss: 26166.1348, D Loss: 0.0000\n",
      "Epoch [1/10], Step [2661/10000], G Loss: 22715.9375, D Loss: 0.0000\n",
      "Epoch [1/10], Step [2671/10000], G Loss: 25352.6602, D Loss: 0.0000\n",
      "Epoch [1/10], Step [2681/10000], G Loss: 19544.6680, D Loss: 0.0000\n",
      "Epoch [1/10], Step [2691/10000], G Loss: 26037.0469, D Loss: 1.7334\n",
      "Epoch [1/10], Step [2701/10000], G Loss: 26004.0840, D Loss: 0.0001\n",
      "Epoch [1/10], Step [2711/10000], G Loss: 26598.8027, D Loss: 5.6043\n",
      "Epoch [1/10], Step [2721/10000], G Loss: 22999.8398, D Loss: 0.0113\n",
      "Epoch [1/10], Step [2731/10000], G Loss: 28059.8906, D Loss: 0.0033\n",
      "Epoch [1/10], Step [2741/10000], G Loss: 25198.9258, D Loss: 0.0102\n",
      "Epoch [1/10], Step [2751/10000], G Loss: 20168.8203, D Loss: 0.0022\n"
     ]
    }
   ],
   "source": [
    "# 훈련 루프\n",
    "num_epochs = 10\n",
    "output_dir = 'output_images'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (gothic, handwriting) in enumerate(dataloader):\n",
    "        gothic, handwriting = gothic.to(device), handwriting.to(device)\n",
    "        batch_size = gothic.size(0)\n",
    "\n",
    "        # 판별자 출력 크기에 맞춰 목표 텐서 크기 조정\n",
    "        valid = torch.ones(discriminator(handwriting).size(), requires_grad=False).to(device)\n",
    "        fake = torch.zeros(discriminator(handwriting).size(), requires_grad=False).to(device)\n",
    "\n",
    "        # ---------------------\n",
    "        #  Train VAE (Generator)\n",
    "        # ---------------------\n",
    "        optimizer_G.zero_grad()\n",
    "\n",
    "        recon_gothic, mu, logvar = vae(gothic)\n",
    "        # handwriting 이미지를 recon_gothic와 동일한 크기로 변환\n",
    "        handwriting_resized = torch.nn.functional.interpolate(handwriting, size=recon_gothic.shape[2:], mode='bilinear')\n",
    "\n",
    "        vae_loss = vae_loss_function(recon_gothic, handwriting_resized, mu, logvar)\n",
    "        g_adv_loss = adversarial_loss(discriminator(recon_gothic), valid)\n",
    "\n",
    "        g_loss = vae_loss + 0.1 * g_adv_loss  # 가중치를 조정하여 손실 함수의 균형 맞추기\n",
    "        g_loss.backward()\n",
    "        nn.utils.clip_grad_norm_(vae.parameters(), max_norm=1.0)  # Gradient Clipping\n",
    "        optimizer_G.step()\n",
    "\n",
    "        # ---------------------\n",
    "        #  Train Discriminator\n",
    "        # ---------------------\n",
    "        optimizer_D.zero_grad()\n",
    "\n",
    "        real_loss = adversarial_loss(discriminator(handwriting), valid)\n",
    "        fake_loss = adversarial_loss(discriminator(recon_gothic.detach()), fake)\n",
    "        d_loss = (real_loss + fake_loss) / 2\n",
    "\n",
    "        d_loss.backward()\n",
    "        nn.utils.clip_grad_norm_(discriminator.parameters(), max_norm=1.0)  # Gradient Clipping\n",
    "        optimizer_D.step()\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(dataloader)}], G Loss: {g_loss.item():.4f}, D Loss: {d_loss.item():.4f}\")\n",
    "\n",
    "        # 결과 이미지 저장\n",
    "        if (epoch * len(dataloader) + i) % 10 == 0:\n",
    "            save_generated_images(recon_gothic, 1, epoch=epoch, idx=i)\n",
    "\n",
    "print(\"Training completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fcda53-a39d-4b13-9dda-cbf4fba01911",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337ec027-be0d-4f70-a5eb-a9451b4e056c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aef2990-d92f-4914-8341-279b26b120ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60ed902-40d9-4ac8-b844-edfdaeffea6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ca2a13-e93a-40c3-a16c-a21d973eb7c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
